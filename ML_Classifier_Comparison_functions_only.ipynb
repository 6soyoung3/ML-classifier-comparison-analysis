{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f7a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b64095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filepath):\n",
    "#   sep = none?\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf55620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_2_predictors(dataset1, dataset2, features):\n",
    "    predictor1 = dataset1[features]\n",
    "    predictor2 = dataset2[features]\n",
    "    return predictor1, predictor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80377370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_2_targets(dataset1, dataset2, outcome):\n",
    "    target1 = dataset1[outcome]\n",
    "    target2 = dataset2[outcome]\n",
    "    return target1, target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89386988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_data(dataset_X, dataset_y):\n",
    "    return train_test_split(dataset_X, dataset_y, random_state=1, shuffle = True, stratify=dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e209573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decision_tree(criterion=\"gini\", splitter=\"best\", max_depth=6):\n",
    "    model = DecisionTreeClassifier(criterion=criterion, splitter=splitter, random_state=1, max_depth=max_depth)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d8f3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_decision_tree(train_X, train_y, model):\n",
    "    model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab96f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_decision_tree(model, testcases):\n",
    "    return model.predict(testcases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e42b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(testcases, prediction_result):\n",
    "    return accuracy_score(testcases, prediction_result) * 100.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1237ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree_agreed_disagreed(all_cases, features):\n",
    "    train_X = all_cases[features]\n",
    "    train_y = all_cases.Agreed\n",
    "    model = create_decision_tree()\n",
    "    fit_decision_tree(train_X, train_y, model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d38e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names e.g. ['0', '1']\n",
    "def visualise_decision_tree(model, features, class_names):\n",
    "    fig = plt.figure(figsize=(40,20))\n",
    "    visualisation = tree.plot_tree(model, feature_names=features, class_names=class_names, filled=True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa22f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ML_model(file_name_for_save, model_to_save):\n",
    "    filehandler = open(file_name_for_save + '.obj', 'wb') \n",
    "    pickle.dump(model_to_save, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1843b746",
   "metadata": {},
   "source": [
    "# For users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c74c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ML_model(file_to_open):\n",
    "    filehandler = open(file_to_open, 'rb') \n",
    "    return pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca5dcac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(prediction_result1, prediction_result2):\n",
    "    return accuracy_score(prediction_result1, prediction_result2) * 100.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e4baace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_disagreed_cases(testcases, similarity):\n",
    "    wrong_proportion = 1 - (similarity / 100)\n",
    "    return round(len(testcases) * wrong_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8515b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_disagreed_cases(testcases, prediction_result1, prediction_result2):\n",
    "    filters = np.logical_xor(prediction_result1, prediction_result2)\n",
    "    disagreed = testcases[filters]\n",
    "    disagreed['Agreed'] = 0\n",
    "    return disagreed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0530569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_agreed_cases(testcases, prediction_result1, prediction_result2):\n",
    "    filters = return_disagreed_cases(testcases,prediction_result1, prediction_result2)\n",
    "    agreed = testcases.loc[testcases.index.difference(filters.index)]\n",
    "    agreed['Agreed'] = 1\n",
    "    return agreed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d7d29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disagreed_LIME(train1, train2, all_disagreed_testcases, model1, model2, features, classes):\n",
    "    train1_numpy = train1.to_numpy()\n",
    "    train2_numpy = train2.to_numpy()\n",
    "    all_disagreed_testcases_numpy = all_disagreed_testcases[features].to_numpy()\n",
    "\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(train1_numpy,\n",
    "                                                       feature_names=features,\n",
    "                                                       class_names=classes,\n",
    "                                                       discretize_continuous=True)\n",
    "\n",
    "    i = np.random.randint(0, len(all_disagreed_testcases_numpy))\n",
    "    disagreed_case = all_disagreed_testcases_numpy[i]\n",
    "\n",
    "    exp1 = explainer.explain_instance(disagreed_case, model1.predict_proba, num_features=len(features))\n",
    "    exp1_map = exp1.as_map()\n",
    "    exp1.show_in_notebook()\n",
    "\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(train2_numpy,\n",
    "                                                       feature_names=features,\n",
    "                                                       class_names=classes,\n",
    "                                                       discretize_continuous=True)\n",
    "\n",
    "    exp2 = explainer.explain_instance(disagreed_case, model2.predict_proba, num_features=len(features))\n",
    "    exp2_map = exp2.as_map()\n",
    "    exp2.show_in_notebook()\n",
    "    \n",
    "    exp1_result = classes[model1.predict(disagreed_case.reshape(1,-1))[0]]\n",
    "    exp2_result = classes[model2.predict(disagreed_case.reshape(1,-1))[0]]\n",
    "    \n",
    "    return exp1_map[1], exp2_map[1], disagreed_case, exp1_result, exp2_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d3c9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     return feature_importance_output.plot.barh()\n",
    "def print_feature_importance(fittedmodel, features):\n",
    "    feature_importance = fittedmodel.feature_importances_\n",
    "    feature_importance_output = pd.DataFrame(feature_importance, features)\n",
    "    feature_importance_output.set_axis(['Output'], axis=1, inplace=True)\n",
    "    print(feature_importance_output)\n",
    "    ax = feature_importance_output.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78422e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_for_disagreement(features, agreed_cases, disagreed_cases, model = None):\n",
    "    all_cases = pd.DataFrame(agreed_cases.append(disagreed_cases))\n",
    "    X_train = all_cases[features]\n",
    "    y_train = all_cases['Agreed']\n",
    "    if model == None:\n",
    "        model = create_decision_tree()\n",
    "        fit_decision_tree(X_train, y_train, model)\n",
    "    print_feature_importance(model, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce0a1d1",
   "metadata": {},
   "source": [
    "labels = [class1_v1, class2_v1, …classk_v1,\n",
    "          class1, class2, …, classk, \n",
    "               class1_v2, class2_v2, …, classk_v2] // 3k labels <br>\n",
    "\n",
    "Source = [0, 0, …, 0, 1,1,..., 1, … {k blocks}, \n",
    "\t    k, k, …, k, k+1, k+1, …, k+1, k+2, … ] // k*k*2 <br>\n",
    "        \n",
    "Target = [k, k+1, …, 2k {each of the ground truth classes}, k, k+1, …,{k blocks of k length}\n",
    "                2k, 2k+1, …, 3k-1, 2k, 2k+1, …, 3k-1, … {k blocks of k length} ] // k*k*2 <br>\n",
    "                \n",
    "Value = [num(predicted class1 by v1 that are of class1), \n",
    "              num(predicted class1 by v1 that are of class2), …,\n",
    "              num(predicted class1 by v1 that are of classk),\n",
    "\t…,\n",
    "              num(class 1 where v2 predicted class1), {source k to target 2k}\n",
    "              num(class 1 where v2 predicted class2), {source k to target 2k+1}…,\n",
    "              num(class 1 where v2 predicted classk),\n",
    "              … ] // k*k*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc378f9a",
   "metadata": {},
   "source": [
    "labels = ['Younger Diabetes', 'Younger No Diabetes', 'Diabetes', 'No Diabetes', 'Older Diabetes', 'Older No Diabetes']\n",
    "\n",
    "sources = [0, 0, 1, 1, 4, 4, 5, 5] \n",
    "\n",
    "targets = [2, 3, 2, 3, 2, 3, 2, 3]\n",
    "\n",
    "- #num(predicted class1 by v1 that are of class1), \n",
    "- #num(predicted class1 by v1 that are of class2), …,\n",
    "\n",
    "values = [younger_y_pred_confusion[1][1], younger_y_pred_confusion[1][0],\n",
    "          younger_y_pred_confusion[0][1], younger_y_pred_confusion[0][0],\n",
    "          older_y_pred_opposite_confusion[1][1], older_y_pred_opposite_confusion[1][0],\n",
    "          older_y_pred_opposite_confusion[0][1], older_y_pred_opposite_confusion[0][0],]\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = labels,\n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = sources,\n",
    "      target = targets,\n",
    "      value = values\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Sankey Diagram\", font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfb89909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sankey_diagram(confusion_matrix1, confusion_matrix2, classes):\n",
    "    number_of_classes = len(classes) # 2\n",
    "    \n",
    "    labels = classes * 3\n",
    "    \n",
    "    sources = list()\n",
    "    for i in range(0, number_of_classes * number_of_classes):\n",
    "        for j in range(1, 1 + number_of_classes):\n",
    "            sources.append(i)\n",
    "    \n",
    "    targets = list()\n",
    "    for i in range(number_of_classes):\n",
    "        for j in range(number_of_classes, 2 * number_of_classes):\n",
    "            targets.append(j)\n",
    "    for i in range(number_of_classes):\n",
    "        for j in range(2 * number_of_classes, 3 * number_of_classes):\n",
    "            targets.append(j)\n",
    "    \n",
    "    values = [confusion_matrix1[1][1], confusion_matrix1[0][1],\n",
    "             confusion_matrix1[1][0], confusion_matrix1[0][0],\n",
    "             confusion_matrix2[1][1], confusion_matrix2[0][1],\n",
    "             confusion_matrix2[1][0], confusion_matrix2[0][0]]\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node = dict(\n",
    "            pad = 15,\n",
    "            thickness = 20,\n",
    "            line = dict(color = \"black\", width = 0.5),\n",
    "            label = labels,\n",
    "            color = \"blue\"\n",
    "        ),\n",
    "        link = dict(\n",
    "            source = sources,\n",
    "            target = targets,\n",
    "            value = values\n",
    "        ))])\n",
    "\n",
    "    fig.update_layout(title_text=\"Sankey Diagram\", font_size=10)\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
