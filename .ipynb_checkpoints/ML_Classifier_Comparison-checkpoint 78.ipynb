{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4035732",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300eafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "import holoviews as hv\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from ipysankeywidget import SankeyWidget\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2041b",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a78dc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb\n",
    "from ipynb.fs.defs.ML_Classifier_Comparison_Functions_Only import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c476583",
   "metadata": {},
   "source": [
    "# Read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c77538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetesData = read_csv('Data/diabetes.csv')\n",
    "diabetesData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a983c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetesData.isnull().values.any() # for checking any missing value\n",
    "# False means there is not missing value in this database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad81f4d7",
   "metadata": {},
   "source": [
    "# Choose the most appropriate pivot\n",
    "- Why did you choose 'Age'? What is the relationship between the Age and the Outcome?\n",
    "    - if the average of 'Age's were the same(i.e. the range is small) -> no point\n",
    "    - if the difference between Ages is big -> likely to be a good predictor(affected hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75145834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.298000</td>\n",
       "      <td>109.980000</td>\n",
       "      <td>68.184000</td>\n",
       "      <td>19.664000</td>\n",
       "      <td>68.792000</td>\n",
       "      <td>30.304200</td>\n",
       "      <td>0.429734</td>\n",
       "      <td>31.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.865672</td>\n",
       "      <td>141.257463</td>\n",
       "      <td>70.824627</td>\n",
       "      <td>22.164179</td>\n",
       "      <td>100.335821</td>\n",
       "      <td>35.142537</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>37.067164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "Outcome                                                                      \n",
       "0           3.298000  109.980000      68.184000      19.664000   68.792000   \n",
       "1           4.865672  141.257463      70.824627      22.164179  100.335821   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction        Age  \n",
       "Outcome                                                  \n",
       "0        30.304200                  0.429734  31.190000  \n",
       "1        35.142537                  0.550500  37.067164  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure out which predictor column has contributed to 'outcome == 1' the most\n",
    "averages_for_each_outcome = diabetesData.groupby(['Outcome']).mean()\n",
    "averages_for_each_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26888627",
   "metadata": {},
   "source": [
    "# Check the proportion of each outcome in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54997ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 500 0s and 268 1s in diabetes dataset\n",
      "Hence, 34.9% percent of outcomes are 1\n"
     ]
    }
   ],
   "source": [
    "proportion = diabetesData['Outcome'].value_counts()\n",
    "print('There are %d 0s and %d 1s in diabetes dataset' % (proportion[0], proportion[1]))\n",
    "print('Hence, %.1f%% percent of outcomes are 1' %(proportion[1]/len(diabetesData) * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5378c",
   "metadata": {},
   "source": [
    "# Divide datasets into 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c6bda2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetesData['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6fd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the database into 2 such that 2 classifiers can be generated on different datasets\n",
    "youngerDiabetes = diabetesData[diabetesData['Age'] < 29]\n",
    "olderDiabetes = diabetesData[diabetesData['Age'] >= 29]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24016de0",
   "metadata": {},
   "source": [
    "# Create and Train 2 decision tree classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dba894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features (all columns except 'outcome')\n",
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "target = ['Outcome']\n",
    "\n",
    "# data of X (predictors)\n",
    "younger_X, older_X = split_to_2_predictors(youngerDiabetes, olderDiabetes, features)\n",
    "# data of Y (target)\n",
    "younger_y, older_y = split_to_2_targets(youngerDiabetes, olderDiabetes, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fb41473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into validation(testing) and training\n",
    "# the default test_size is 0.25 given not specifying both train_size and test_size (train_size = 0.75\n",
    "# and 25:75 is good rool of thumb\n",
    "# 'stratify' - It makes a split such that the proportion of values in the sample produced\n",
    "# will be the same as the proportion of values provided to the parameter stratify\n",
    "younger_X_train, younger_X_test, younger_y_train, younger_y_test = train_test_split_data(younger_X, younger_y)\n",
    "older_X_train, older_X_test, older_y_train, older_y_test = train_test_split_data(older_X, older_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71eeb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify decision tree model\n",
    "# explore this later to justify why depth=10 (could be 5? or smaller)\n",
    "younger_decisionTree_model = create_decision_tree()\n",
    "older_decisionTree_model = create_decision_tree()\n",
    "\n",
    "# train(fit) decision tree classifier\n",
    "fit_decision_tree(younger_X_train, younger_y_train, younger_decisionTree_model)\n",
    "fit_decision_tree(older_X_train, older_y_train, older_decisionTree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a30fefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test cases to examine the performance of classifiers\n",
    "total_testcases = pd.DataFrame(older_X_test.append(younger_X_test))\n",
    "total_testoutcome = pd.DataFrame(older_y_test.append(younger_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc15b29",
   "metadata": {},
   "source": [
    "# Print accuracies and precisions of classifiers\n",
    "## Improve these accuracies to make more realistic! (explore this later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc103c",
   "metadata": {},
   "source": [
    "### Accuracy = a ratio of correctly predicted observation to the total observations\n",
    "- A great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same\n",
    "- Accuracy = TP+TN/TP+FP+FN+TN\n",
    "\n",
    "### Precision = a ratio of correctly predicted positive observations to the total predicted positive observations\n",
    "- High precision relates to the low false positive rate\n",
    "- Precision = TP/TP+FP\n",
    "\n",
    "-- Source: https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "           https://towardsdatascience.com/machine-learning-classifiers-comparison-with-python-33149aecdbca\n",
    "           https://towardsdatascience.com/various-ways-to-evaluate-a-machine-learning-models-performance-230449055f15\n",
    "           https://medium.com/@vaibhavpaliwal/comparing-machine-learning-algorithms-on-a-single-dataset-classification-46ffc5d3f278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9b420e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 'younger' decision tree against 'younger' test: 80.43478260869566\n",
      "Accuracy of 'younger' decision tree against 'older' test: 57.42574257425742\n",
      "Accuracy of 'older' decision tree against 'older' test: 66.33663366336634\n",
      "Accuracy of 'older' decision tree against 'younger' test: 63.04347826086957\n",
      "\n",
      "\n",
      "How similar the results of older tree and younger tree tested against 'younger' testcases are: 60.86956521739131\n",
      "How similar the results of older tree and younger tree tested against 'older' testcases are: 57.42574257425742\n",
      "-- These tell me how similar the 2 trained decision classifiers are\n",
      "-- There are 92 test cases in younger, and 101 test cases in older\n",
      "-- Given that they the similarity was approximately 60.87% percent over 'younger' testcases, around -5508 testcases were disagreed\n",
      "-- Given that they the similarity was approximately 57.43% percent over 'older' testcases, around -5699 testcases were disagreed\n"
     ]
    }
   ],
   "source": [
    "# predict the response for test dataset\n",
    "older_y_pred = test_decision_tree(older_decisionTree_model, older_X_test)\n",
    "older_y_pred_opposite = test_decision_tree(older_decisionTree_model, younger_X_test)\n",
    "\n",
    "younger_y_pred = test_decision_tree(younger_decisionTree_model, younger_X_test)\n",
    "younger_y_pred_opposite = younger_decisionTree_model.predict(older_X_test)\n",
    "\n",
    "print(\"Accuracy of 'younger' decision tree against 'younger' test:\", calculate_accuracy(younger_y_test, younger_y_pred))\n",
    "print(\"Accuracy of 'younger' decision tree against 'older' test:\", calculate_accuracy(older_y_test, younger_y_pred_opposite))\n",
    "print(\"Accuracy of 'older' decision tree against 'older' test:\", calculate_accuracy(older_y_test, older_y_pred))\n",
    "print(\"Accuracy of 'older' decision tree against 'younger' test:\", calculate_accuracy(younger_y_test, older_y_pred_opposite))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# tells me how those 2 classifiers are similar to each other\n",
    "younger_testcases_predictions_similarity = calculate_similarity(older_y_pred_opposite, younger_y_pred)\n",
    "older_testcases_predictions_similarity = calculate_similarity(younger_y_pred_opposite, older_y_pred)\n",
    "\n",
    "print(\"How similar the results of older tree and younger tree tested against 'younger' testcases are:\", younger_testcases_predictions_similarity)\n",
    "print(\"How similar the results of older tree and younger tree tested against 'older' testcases are:\", older_testcases_predictions_similarity)\n",
    "print(\"-- These tell me how similar the 2 trained decision classifiers are\")\n",
    "\n",
    "print(\"-- There are %d test cases in younger, and %d test cases in older\" %(len(younger_X_test), len(older_X_test)))\n",
    "\n",
    "print(\"-- Given that they the similarity was approximately %.2f%% percent over 'younger' testcases, around %d testcases were disagreed\" %(younger_testcases_predictions_similarity, number_of_disagreed_cases(younger_X_test, younger_testcases_predictions_similarity)))\n",
    "print(\"-- Given that they the similarity was approximately %.2f%% percent over 'older' testcases, around %d testcases were disagreed\" %(older_testcases_predictions_similarity, number_of_disagreed_cases(older_X_test, older_testcases_predictions_similarity)))\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c50d3402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision: 0.28019323671497587\n",
      "Average precision: 0.6039168316831683\n"
     ]
    }
   ],
   "source": [
    "print(\"Average precision:\", average_precision_score(younger_y_test, younger_y_pred))\n",
    "print(\"Average precision:\", average_precision_score(older_y_test, older_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662955c",
   "metadata": {},
   "source": [
    "# Optimising decision tree performance\n",
    "### Decision Tree Criterion\n",
    "- {“gini”, “entropy”}, default=”gini”\n",
    "- Both gini and entropy options are measures of 'impurity' of a node. A node having multiple classes is impure while a node having only one class is pure (most leaves are pure unless the tree has no attributes to split further on)\n",
    "### Decision Tree Splitter\n",
    "- {“best”, “random”}, default=”best”\n",
    "- \"best\" evaluates every split using criterion then split the node with the best one while \"random\" \n",
    "### Decision Tree Max Depth\n",
    "- int or None, optional (default = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40439b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 'younger gini' decision tree against 'younger' test: 0.8043478260869565\n",
      "Accuracy of 'older gini' decision tree against 'older' test: 0.6633663366336634\n",
      "Accuracy of 'younger entropy' decision tree against 'younger' test: 0.8043478260869565\n",
      "Accuracy of 'older entropy' decision tree against 'older' test: 0.6138613861386139\n"
     ]
    }
   ],
   "source": [
    "younger_entropy_decisionTree_model = DecisionTreeClassifier(criterion='entropy', random_state=1, max_depth=6)\n",
    "older_entropy_decisionTree_model = DecisionTreeClassifier(criterion='entropy', random_state=1, max_depth=6)\n",
    "younger_entropy_decisionTree_model.fit(younger_X_train, younger_y_train)\n",
    "older_entropy_decisionTree_model.fit(older_X_train, older_y_train)\n",
    "younger_entropy_pred = younger_entropy_decisionTree_model.predict(younger_X_test)\n",
    "older_entropy_pred = older_entropy_decisionTree_model.predict(older_X_test)\n",
    "\n",
    "print(\"Accuracy of 'younger gini' decision tree against 'younger' test:\", accuracy_score(younger_y_test, younger_y_pred))\n",
    "print(\"Accuracy of 'older gini' decision tree against 'older' test:\", accuracy_score(older_y_test, older_y_pred))\n",
    "print(\"Accuracy of 'younger entropy' decision tree against 'younger' test:\", accuracy_score(younger_y_test, younger_entropy_pred))\n",
    "print(\"Accuracy of 'older entropy' decision tree against 'older' test:\", accuracy_score(older_y_test, older_entropy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f4a95",
   "metadata": {},
   "source": [
    "# WHY did they disagreed on those cases?\n",
    "- Use feature_importance\n",
    "- Train a new classifier which has new labels e.g. train on the same dataset but use for comparison but the labels will be whether they disagree or not...\n",
    "- The datasets we used for comparison was younger_X_test\n",
    "- Whether they disagree or not (the labels = np.logical_xor(older_y_pred_opposite, younger_y_pred)) this is the TARGET\n",
    "- Don't train/test split just use all of them for training!! \n",
    "- For this ML classifier, print feature_importance_ (high importance tells me why they disagreed)\n",
    "- No decision tree? Use logistic regression..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82420afa",
   "metadata": {},
   "source": [
    "# Print feature_importance_ of younger testcases classifier\n",
    "- This tells me which features effected how significantly on making disagreement between classifiers\n",
    "- They are computed as the mean and standard deviation of accumulation of the impurity decrease within tree\n",
    "- The importance of a feature is: how much this feature is used in tree. Formally, it is computed as the (normalized) total reduction of the criterion brought by that feature\n",
    "-- source: https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "-- source: https://inria.github.io/scikit-learn-mooc/python_scripts/dev_features_importance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dc49d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Output\n",
      "Pregnancies               0.000000\n",
      "Glucose                   0.286062\n",
      "BloodPressure             0.164030\n",
      "SkinThickness             0.022817\n",
      "Insulin                   0.085748\n",
      "BMI                       0.336763\n",
      "DiabetesPedigreeFunction  0.104580\n",
      "Age                       0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.28606194, 0.1640297 , 0.02281746, 0.08574796,\n",
       "       0.33676292, 0.10458003, 0.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Computing the disagreed cases (i.e. either when A right but B wrong / A wrong but B right)\n",
    "younger_disagreed_testcases = return_disagreed_cases(younger_X_test, older_y_pred_opposite, younger_y_pred)\n",
    "younger_agreed_testcases = return_agreed_cases(younger_X_test, older_y_pred_opposite, younger_y_pred)\n",
    "\n",
    "all_younger_testcases = pd.DataFrame(younger_disagreed_testcases.append(younger_agreed_testcases))\n",
    "\n",
    "# don't test this ML classifier\n",
    "# data of X (predictors)\n",
    "younger_testcases_X_train = all_younger_testcases[features]\n",
    "\n",
    "# data of Y (target)\n",
    "younger_testcases_y_train = all_younger_testcases['Agreed']\n",
    "\n",
    "younger_testcases_decisionTree_model = create_decision_tree() # explore this later to justify why depth=10 (could be 5? or smaller)\n",
    "\n",
    "# train(fit) decision tree classifier\n",
    "\n",
    "fit_decision_tree(younger_testcases_X_train, younger_testcases_y_train, younger_testcases_decisionTree_model)\n",
    "\n",
    "print_feature_importance(younger_testcases_decisionTree_model, features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50a00f",
   "metadata": {},
   "source": [
    "# Print feature_importance_ of older testcases classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the disagreed cases (i.e. either when A right but B wrong / A wrong but B right)\n",
    "\n",
    "older_disagreed_testcases = return_disagreed_cases(older_X_test, younger_y_pred_opposite, older_y_pred)\n",
    "older_agreed_testcases = return_agreed_cases(older_X_test, younger_y_pred_opposite, older_y_pred)\n",
    "\n",
    "all_older_testcases = pd.DataFrame(older_disagreed_testcases.append(older_agreed_testcases))\n",
    "\n",
    "# don't test this ML classifier\n",
    "# data of X (predictors)\n",
    "older_testcases_X_train = all_older_testcases[features]\n",
    "\n",
    "# data of Y (target)\n",
    "older_testcases_y_train = all_older_testcases['Agreed']\n",
    "\n",
    "older_testcases_decisionTree_model = create_decision_tree() # explore this later to justify why depth=10 (could be 5? or smaller)\n",
    "\n",
    "# train(fit) decision tree classifier\n",
    "\n",
    "fit_decision_tree(older_testcases_X_train, older_testcases_y_train, older_testcases_decisionTree_model)\n",
    "\n",
    "print_feature_importance(older_testcases_decisionTree_model, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bebd25",
   "metadata": {},
   "source": [
    "# In which feature does each classifier rely on most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ebb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "younger_importance=print_feature_importance(younger_decisionTree_model, features)\n",
    "print(\"\\n\")\n",
    "older_importance=print_feature_importance(older_decisionTree_model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how the two different classifiers rely on features\n",
    "print(younger_importance - older_importance)\n",
    "print(\"The output tells me Pregnancies, BloodPressure, Insulin and BMI features were more important in younger classifier\")\n",
    "print(\"While Glucose, DiabetesPedigreeFunction and Age features were more important in Older\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c8eff",
   "metadata": {},
   "source": [
    "# Lime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb413d35",
   "metadata": {},
   "source": [
    "-- Younger\n",
    "- Left shows prediction probability of the two classes\n",
    "- The middle chart shows the important features with their bounding values and the right table is the actual corresponding feature value in the observation row passed\n",
    "-- source: https://towardsdatascience.com/a-guide-to-interpretable-machine-learning-2-fa3c4489fb53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629dbdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the disagreed cases (i.e. either when A right but B wrong / A wrong but B right)\n",
    "classes=['Agreed','Disagreed']\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(all_younger_testcases[features].to_numpy(),\n",
    "                                                   feature_names=features,\n",
    "                                                   class_names=classes,\n",
    "                                                   discretize_continuous=True)\n",
    "\n",
    "all_younger_testcases = all_younger_testcases.merge(younger_disagreed_testcases, how = 'right')\n",
    "\n",
    "i = np.random.randint(0, all_younger_testcases.index.to_numpy().size)\n",
    "\n",
    "exp = explainer.explain_instance(all_younger_testcases[features].iloc[i], younger_testcases_decisionTree_model.predict_proba, num_features=8, top_labels=1)\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d264215",
   "metadata": {},
   "source": [
    "# Explain for each classifier why they showed disagreement\n",
    "## Sample disagreed ones (merge two testcases and just sample more than one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0936b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train using test cases where the labels are Agree and Disagree (0 and 1)\n",
    "all_disagreed_testcases = pd.DataFrame(younger_disagreed_testcases.append(older_disagreed_testcases))\n",
    "all_disagreed_testcases['Agreed'] = 0\n",
    "all_agreed_testcases = pd.DataFrame(younger_agreed_testcases.append(older_agreed_testcases))\n",
    "all_agreed_testcases['Agreed'] = 1\n",
    "\n",
    "# younger_disagreed + older_disagreed + younger_agreed + older_agreed\n",
    "all_testcases = pd.DataFrame(all_agreed_testcases.append(all_disagreed_testcases))\n",
    "all_testcases_pridictors = all_testcases[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_testcases))\n",
    "print(len(all_disagreed_testcases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify decision tree model\n",
    "all_testcases_decisionTree_model = create_decision_tree() # explore this later to justify why depth=10 (could be 5? or smaller)\n",
    "\n",
    "# train(fit) decision tree classifier\n",
    "all_testcases_decisionTree_model.fit(all_testcases_pridictors, all_testcases.Agreed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77cd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(all_testcases_pridictors.values,\n",
    "                                                   feature_names=features,\n",
    "                                                   class_names=['Agreed','Disagreed'],\n",
    "                                                   discretize_continuous=True)\n",
    "\n",
    "all_testcases_decisionTree_model = create_decision_tree()\n",
    "\n",
    "all_testcases_decisionTree_model.fit(all_testcases_pridictors, all_testcases.Agreed)\n",
    "\n",
    "all_testcases = all_testcases.merge(all_disagreed_testcases, how = 'right')\n",
    "\n",
    "i = np.random.randint(0, all_disagreed_testcases.index.to_numpy().size)\n",
    "\n",
    "exp = explainer.explain_instance(all_testcases_pridictors.iloc[i], all_testcases_decisionTree_model.predict_proba, num_features=8, top_labels=1)\n",
    "exp.show_in_notebook()\n",
    "\n",
    "print(exp.as_map())\n",
    "print(\"\\n\")\n",
    "print(exp.as_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b0b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(younger_testcases_X_train.values,\n",
    "                                                   mode='classification',\n",
    "                                                   feature_names=features,\n",
    "                                                   class_names=['Disagreed','Agreed'],\n",
    "                                                   discretize_continuous=True)\n",
    "i = np.random.randint(0, younger_testcases_X_train.shape[0])\n",
    "exp = explainer.explain_instance(younger_testcases_X_train.iloc[i], younger_testcases_decisionTree_model.predict_proba, num_features=8, top_labels=1)\n",
    "exp.show_in_notebook()\n",
    "print(younger_testcases_y_train.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bdfc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(younger_X_train.values,\n",
    "                                                   feature_names=features,\n",
    "                                                   class_names=['Diabetes','No Diabetes'],\n",
    "                                                   discretize_continuous=True)\n",
    "i = np.random.randint(0, younger_X_test.shape[0])\n",
    "\n",
    "## younger / older classifiers\n",
    "## sample disagreed ones (merge two testcases and just sample more than one...)\n",
    "## explain -> for each classifier, why they show disagreement\n",
    "\n",
    "exp = explainer.explain_instance(younger_X_test.iloc[i], younger_decisionTree_model.predict_proba, num_features=8)\n",
    "#print(younger_decisionTree_model.predict_proba(younger_X_test.iloc[i]))\n",
    "print(younger_y_test.iloc[i])\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d6875",
   "metadata": {},
   "source": [
    "### Pick disagreed ones\n",
    "### test on both younger_decisiontree_model and older_decisiontree_model\n",
    "### show they results differently (one says diabetes while other says no diabetes) with LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd90480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(younger_X_train.values,\n",
    "                                                   feature_names=features,\n",
    "                                                   class_names=['Diabetes','No Diabetes'],\n",
    "                                                   discretize_continuous=True)\n",
    "\n",
    "younger_X_test = younger_X_test.merge(all_disagreed_testcases, how = 'right')\n",
    "i = np.random.randint(0, all_disagreed_testcases.index.to_numpy().size)\n",
    "# i = np.random.randint(0, younger_X_test.shape[0])\n",
    "\n",
    "exp = explainer.explain_instance(younger_X_test.iloc[i], younger_decisionTree_model.predict_proba, num_features=8)\n",
    "#print(younger_decisionTree_model.predict_proba(younger_X_test.iloc[i]))\n",
    "print(younger_y_test.iloc[i])\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f148e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(younger_X_train.values,\n",
    "                                                   feature_names=features,\n",
    "                                                   class_names=['Diabetes','No Diabetes'],\n",
    "                                                   discretize_continuous=True)\n",
    "i = np.random.randint(0, younger_X_test.shape[0])\n",
    "\n",
    "## younger / older classifiers\n",
    "## sample disagreed ones (merge two testcases and just sample more than one...)\n",
    "## explain -> for each classifier, why they show disagreement\n",
    "\n",
    "exp = explainer.explain_instance(younger_X_test.iloc[i], younger_decisionTree_model.predict_proba, num_features=8)\n",
    "#print(younger_decisionTree_model.predict_proba(younger_X_test.iloc[i]))\n",
    "print(younger_y_test.iloc[i])\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e81480",
   "metadata": {},
   "source": [
    "# Sankey diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: agreed and disagreed from younger - all_younger_testcases\n",
    "# target: agreed and disagreed from older - all_older_testcases\n",
    "# all_younger_testcases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6501636",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = [\"Younger Diabetes\", \"Older Diabetes\", \"None\", \"None\"],\n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = [1, 0, 0, 1, 0],\n",
    "      target = [0, 1, 3 ,2, 2],\n",
    "      value = [len(younger_agreed_testcases), len(older_agreed_testcases), len(older_disagreed_testcases), len(younger_disagreed_testcases), 0]\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Sankey Diagram\", font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd914285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# younger_disagreed_testcases = return_disagreed_cases(younger_X_test, older_y_pred_opposite, younger_y_pred)\n",
    "# younger_agreed_testcases = return_agreed_cases(younger_X_test, older_y_pred_opposite, younger_y_pred)\n",
    "\n",
    "# older_disagreed_testcases = return_disagreed_cases(older_X_test, younger_y_pred_opposite, older_y_pred)\n",
    "# older_agreed_testcases = return_agreed_cases(older_X_test, younger_y_pred_opposite, older_y_pred)\n",
    "\n",
    "print(len(younger_agreed_testcases))\n",
    "print(len(younger_disagreed_testcases))\n",
    "print(len(older_agreed_testcases))\n",
    "print(len(older_disagreed_testcases))\n",
    "print(\"\\n\")\n",
    "print(len(younger_X_test)) # younger_agreed_testcases + younger_disagreed_testcases\n",
    "print(len(older_X_test)) # older_agreed_testcases + older_disagreed_testcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af48950",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = [\"Younger Diabetes Model\", \"Older Diabetes Model\"],\n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = [0, 1, 1, 0],\n",
    "      target = [1, 0, 0, 1],\n",
    "      value = [len(younger_agreed_testcases), len(older_agreed_testcases), len(older_disagreed_testcases), len(younger_disagreed_testcases)]\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Sankey Diagram\", font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = [\"Younger Diabetes Model\", \"Older Diabetes Model\", \"Agreed\", \"Disagreed\"],\n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = [0, 1, 1, 0],\n",
    "      target = [2, 2, 3, 3],\n",
    "      value = [len(younger_agreed_testcases), len(older_agreed_testcases), len(older_disagreed_testcases), len(younger_disagreed_testcases)]\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Sankey Diagram\", font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9047d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [class1_v1, class2_v1, …classk_v1,\n",
    "          class1, class2, …, classk, \n",
    "               class1_v2, class2_v2, …, classk_v2] // 3k labels\n",
    "\n",
    "Source = [0, 0, …, 0, 1,1,..., 1, … {k blocks}, \n",
    "\t    k, k, …, k, k+1, k+1, …, k+1, k+2, … ] // k*k*2\n",
    "Target = [k, k+1, …, 2k {each of the ground truth classes}, k, k+1, …,{k blocks of k length}\n",
    "                2k, 2k+1, …, 3k-1, 2k, 2k+1, …, 3k-1, … {k blocks of k length} ] // k*k*2\n",
    "Value = [num(predicted class1 by v1 that are of class1), \n",
    "              num(predicted class1 by v1 that are of class2), …,\n",
    "              num(predicted class1 by v1 that are of classk),\n",
    "\t…,\n",
    "              num(class 1 where v2 predicted class1), {source k to target 2k}\n",
    "              num(class 1 where v2 predicted class2), {source k to target 2k+1}…,\n",
    "              num(class 1 where v2 predicted classk),\n",
    "              … ] // k*k*2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172651e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(younger_y_test))\n",
    "younger_incorrect_testcases = younger_X_test[np.logical_xor(younger_y_test.to_numpy(), younger_y_pred)]\n",
    "younger_correct_testcases = younger_X_test.loc[younger_X_test.index.difference(younger_incorrect_testcases.index)]\n",
    "\n",
    "older_incorrect_testcases = older_X_test[np.logical_xor(older_y_test.to_numpy(), older_y_pred)]\n",
    "older_correct_testcases = older_X_test.loc[older_X_test.index.difference(older_incorrect_testcases.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = [\"Younger Classifier\", \"Older Classifier\", \"Diabetes\", \"Not Diabetes\", \"None\", \"None\"],\n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = [0, 0, 0, 1],\n",
    "      target = [2, 1, 3 ,2],\n",
    "      value = [len(younger_correct_testcases), ]\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Sankey Diagram\", font_size=10)\n",
    "fig.show()\n",
    "# LEFT: DIABETES(regardless of correct or not corret - then splitted in to correct and x correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2e468",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226319d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_prediction = all_testcases_pridictors.iloc[1]\n",
    "data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n",
    "\n",
    "print(all_testcases_decisionTree_model.predict_proba(data_for_prediction_array))\n",
    "\n",
    "shap_explainer = shap.TreeExplainer(all_testcases_decisionTree_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = shap_explainer.shap_values(data_for_prediction)\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value[1], shap_values[1], data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fcc3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_explainer = shap.TreeExplainer(all_testcases_decisionTree_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = shap_explainer.shap_values(all_testcases_pridictors)\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value[1], shap_values[1], all_testcases_pridictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_explainer = shap.TreeExplainer(all_testcases_decisionTree_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = shap_explainer.shap_values(all_testcases['Agreed'])\n",
    "shap.initjs()\n",
    "# shap.force_plot(explainer.expected_value[0], shxap_values[0][i], X.values[i], feature_names = X.columns)\n",
    "shap.force_plot(shap_explainer.expected_value[0], shap_values[0][0], all_testcases['Agreed'][0],feature_names = all_testcases.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap_explainer = shap.TreeExplainer(younger_decisionTree_model)\n",
    "shap_values = shap_explainer.shap_values(younger_X)\n",
    "shap.summary_plot(shap_values, younger_X, plot_type=\"bar\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap_explainer = shap.TreeExplainer(older_decisionTree_model)\n",
    "shap_values = shap_explainer.shap_values(older_X)\n",
    "shap.summary_plot(shap_values, older_X, plot_type=\"bar\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "all_testcases = pd.DataFrame(all_agreed_testcases.append(all_disagreed_testcases))\n",
    "\n",
    "shap_explainer = shap.TreeExplainer(all_testcases_decisionTree_model)\n",
    "shap_values = shap_explainer.shap_values(all_testcases[features])\n",
    "shap.summary_plot(shap_values, all_testcases[features], plot_type=\"bar\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e01ba",
   "metadata": {},
   "source": [
    "# Visualise decision trees\n",
    "-- Source: https://mljar.com/blog/visualize-decision-tree/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332df7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,20))\n",
    "youngTreeVisualisation = tree.plot_tree(younger_decisionTree_model, feature_names=features, class_names=['0','1'], filled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95792dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,20))\n",
    "oldTreeVisualisation = tree.plot_tree(older_decisionTree_model, feature_names=features, class_names=str(olderDiabetes.Outcome), filled=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
