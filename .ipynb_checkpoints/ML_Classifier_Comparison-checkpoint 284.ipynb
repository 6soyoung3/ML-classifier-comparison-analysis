{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4035732",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300eafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "import holoviews as hv\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from ipysankeywidget import SankeyWidget\n",
    "\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2041b",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78dc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb\n",
    "from ipynb.fs.defs.ML_Classifier_Comparison_Functions_Only import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c476583",
   "metadata": {},
   "source": [
    "# Read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c77538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetesData = read_csv('Data/diabetes.csv')\n",
    "diabetesData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a983c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetesData.isnull().values.any() # for checking any missing value\n",
    "# False means there is not missing value in this database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad81f4d7",
   "metadata": {},
   "source": [
    "# Choose the most appropriate pivot\n",
    "- Why did you choose 'Age'? What is the relationship between the Age and the Outcome?\n",
    "    - if the average of 'Age's were the same(i.e. the range is small) -> no point\n",
    "    - if the difference between Ages is big -> likely to be a good predictor(affected hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75145834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.298000</td>\n",
       "      <td>109.980000</td>\n",
       "      <td>68.184000</td>\n",
       "      <td>19.664000</td>\n",
       "      <td>68.792000</td>\n",
       "      <td>30.304200</td>\n",
       "      <td>0.429734</td>\n",
       "      <td>31.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.865672</td>\n",
       "      <td>141.257463</td>\n",
       "      <td>70.824627</td>\n",
       "      <td>22.164179</td>\n",
       "      <td>100.335821</td>\n",
       "      <td>35.142537</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>37.067164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "Outcome                                                                      \n",
       "0           3.298000  109.980000      68.184000      19.664000   68.792000   \n",
       "1           4.865672  141.257463      70.824627      22.164179  100.335821   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction        Age  \n",
       "Outcome                                                  \n",
       "0        30.304200                  0.429734  31.190000  \n",
       "1        35.142537                  0.550500  37.067164  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure out which predictor column has contributed to 'outcome == 1' the most\n",
    "averages_for_each_outcome = diabetesData.groupby(['Outcome']).mean()\n",
    "averages_for_each_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26888627",
   "metadata": {},
   "source": [
    "# Check the proportion of each outcome in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54997ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 500 0s and 268 1s in diabetes dataset\n",
      "Hence, 34.9% percent of outcomes are 1\n"
     ]
    }
   ],
   "source": [
    "proportion = diabetesData['Outcome'].value_counts()\n",
    "print('There are %d 0s and %d 1s in diabetes dataset' % (proportion[0], proportion[1]))\n",
    "print('Hence, %.1f%% percent of outcomes are 1' %(proportion[1]/len(diabetesData) * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5378c",
   "metadata": {},
   "source": [
    "# Divide datasets into 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c6bda2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetesData['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6fd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the database into 2 such that 2 classifiers can be generated on different datasets\n",
    "youngerDiabetes = diabetesData[diabetesData['Age'] < 29]\n",
    "olderDiabetes = diabetesData[diabetesData['Age'] >= 29]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24016de0",
   "metadata": {},
   "source": [
    "# Create and Train 2 decision tree classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dba894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features (all columns except 'outcome')\n",
    "features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "target = ['Outcome']\n",
    "\n",
    "# data of X (predictors)\n",
    "younger_X, older_X = split_to_2_predictors(youngerDiabetes, olderDiabetes, features)\n",
    "# data of Y (target)\n",
    "younger_y, older_y = split_to_2_targets(youngerDiabetes, olderDiabetes, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fb41473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# splitting into validation(testing) and training\n",
    "# the default test_size is 0.25 given not specifying both train_size and test_size (train_size = 0.75\n",
    "# and 25:75 is good rool of thumb\n",
    "# 'stratify' - It makes a split such that the proportion of values in the sample produced\n",
    "# will be the same as the proportion of values provided to the parameter stratify\n",
    "younger_X_train, younger_X_test, younger_y_train, younger_y_test = train_test_split_data(younger_X, younger_y)\n",
    "older_X_train, older_X_test, older_y_train, older_y_test = train_test_split_data(older_X, older_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71eeb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify decision tree model\n",
    "# explore this later to justify why depth=10 (could be 5? or smaller)\n",
    "younger_decisionTree_model = create_decision_tree()\n",
    "older_decisionTree_model = create_decision_tree()\n",
    "\n",
    "# train(fit) decision tree classifier\n",
    "fit_decision_tree(younger_X_train, younger_y_train, younger_decisionTree_model)\n",
    "fit_decision_tree(older_X_train, older_y_train, older_decisionTree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a30fefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test cases to examine the performance of classifiers\n",
    "total_testcases = pd.DataFrame(older_X_test.append(younger_X_test))\n",
    "total_testoutcome = pd.DataFrame(older_y_test.append(younger_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc15b29",
   "metadata": {},
   "source": [
    "# Print accuracies of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc103c",
   "metadata": {},
   "source": [
    "### Accuracy = a ratio of correctly predicted observation to the total observations\n",
    "- A great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same\n",
    "- Accuracy = TP+TN/TP+FP+FN+TN\n",
    "\n",
    "-- Source: https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "           https://towardsdatascience.com/machine-learning-classifiers-comparison-with-python-33149aecdbca\n",
    "           https://towardsdatascience.com/various-ways-to-evaluate-a-machine-learning-models-performance-230449055f15\n",
    "           https://medium.com/@vaibhavpaliwal/comparing-machine-learning-algorithms-on-a-single-dataset-classification-46ffc5d3f278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9b420e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 'younger' decision tree against 'younger' test: 80.43478260869566\n",
      "Accuracy of 'younger' decision tree against 'older' test: 57.42574257425742\n",
      "Accuracy of 'older' decision tree against 'older' test: 66.33663366336634\n",
      "Accuracy of 'older' decision tree against 'younger' test: 63.04347826086957\n",
      "\n",
      "\n",
      "How similar the results of older tree and younger tree tested against 'younger' testcases are: 60.86956521739131\n",
      "How similar the results of older tree and younger tree tested against 'older' testcases are: 57.42574257425742\n",
      "-- These tell me how similar the 2 trained decision classifiers are\n",
      "-- Given that they the similarity was approximately 60.87% percent over 'younger' testcases, around 36 testcases were disagreed\n",
      "-- Given that they the similarity was approximately 57.43% percent over 'older' testcases, around 43 testcases were disagreed\n"
     ]
    }
   ],
   "source": [
    "# predict the response for test dataset\n",
    "younger_y_pred = test_decision_tree(younger_decisionTree_model, younger_X_test)\n",
    "younger_y_pred_opposite = younger_decisionTree_model.predict(older_X_test)\n",
    "\n",
    "older_y_pred = test_decision_tree(older_decisionTree_model, older_X_test)\n",
    "older_y_pred_opposite = test_decision_tree(older_decisionTree_model, younger_X_test)\n",
    "\n",
    "print(\"Accuracy of 'younger' decision tree against 'younger' test:\", calculate_accuracy(younger_y_test, younger_y_pred))\n",
    "print(\"Accuracy of 'younger' decision tree against 'older' test:\", calculate_accuracy(older_y_test, younger_y_pred_opposite))\n",
    "print(\"Accuracy of 'older' decision tree against 'older' test:\", calculate_accuracy(older_y_test, older_y_pred))\n",
    "print(\"Accuracy of 'older' decision tree against 'younger' test:\", calculate_accuracy(younger_y_test, older_y_pred_opposite))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# tells me how those 2 classifiers are similar to each other\n",
    "younger_testcases_predictions_similarity = calculate_similarity(older_y_pred_opposite, younger_y_pred)\n",
    "older_testcases_predictions_similarity = calculate_similarity(younger_y_pred_opposite, older_y_pred)\n",
    "\n",
    "print(\"How similar the results of older tree and younger tree tested against 'younger' testcases are:\", younger_testcases_predictions_similarity)\n",
    "print(\"How similar the results of older tree and younger tree tested against 'older' testcases are:\", older_testcases_predictions_similarity)\n",
    "print(\"-- These tell me how similar the 2 trained decision classifiers are\")\n",
    "\n",
    "# print(\"-- There are %d test cases in younger, and %d test cases in older\" %(len(younger_X_test), len(older_X_test)))\n",
    "\n",
    "print(\"-- Given that they the similarity was approximately %.2f%% percent over 'younger' testcases, around %d testcases were disagreed\" %(younger_testcases_predictions_similarity, number_of_disagreed_cases(younger_X_test, younger_testcases_predictions_similarity)))\n",
    "print(\"-- Given that they the similarity was approximately %.2f%% percent over 'older' testcases, around %d testcases were disagreed\" %(older_testcases_predictions_similarity, number_of_disagreed_cases(older_X_test, older_testcases_predictions_similarity)))\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662955c",
   "metadata": {},
   "source": [
    "# Optimising decision tree performance\n",
    "### Decision Tree Criterion\n",
    "- {“gini”, “entropy”}, default=”gini”\n",
    "- Both gini and entropy options are measures of 'impurity' of a node. A node having multiple classes is impure while a node having only one class is pure (most leaves are pure unless the tree has no attributes to split further on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40439b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 'younger entropy' decision tree against 'younger' test: 80.43478260869566\n",
      "Accuracy of 'older entropy' decision tree against 'younger' test: 51.08695652173913\n",
      "Accuracy of 'younger entropy' decision tree against 'older' test: 63.366336633663366\n",
      "Accuracy of 'older entropy' decision tree against 'older' test: 61.386138613861384\n"
     ]
    }
   ],
   "source": [
    "younger_entropy_decisionTree_model = create_decision_tree(criterion='entropy')\n",
    "older_entropy_decisionTree_model = create_decision_tree(criterion='entropy')\n",
    "\n",
    "fit_decision_tree(younger_X_train, younger_y_train, younger_entropy_decisionTree_model)\n",
    "fit_decision_tree(older_X_train, older_y_train, older_entropy_decisionTree_model)\n",
    "\n",
    "younger_entropy_pred = test_decision_tree(younger_entropy_decisionTree_model, younger_X_test)\n",
    "younger_entropy_pred_opposite = test_decision_tree(younger_entropy_decisionTree_model, older_X_test)\n",
    "\n",
    "older_entropy_pred = test_decision_tree(older_entropy_decisionTree_model, older_X_test)\n",
    "older_entropy_pred_opposite = test_decision_tree(older_entropy_decisionTree_model, younger_X_test)\n",
    "\n",
    "print(\"Accuracy of 'younger entropy' decision tree against 'younger' test:\", calculate_accuracy(younger_y_test, younger_entropy_pred))\n",
    "print(\"Accuracy of 'older entropy' decision tree against 'younger' test:\", calculate_accuracy(younger_y_test, older_entropy_pred_opposite))\n",
    "print(\"Accuracy of 'younger entropy' decision tree against 'older' test:\", calculate_accuracy(older_y_test, younger_entropy_pred_opposite))\n",
    "print(\"Accuracy of 'older entropy' decision tree against 'older' test:\", calculate_accuracy(older_y_test, older_entropy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b136a2d",
   "metadata": {},
   "source": [
    "### Decision Tree Splitter\n",
    "- {“best”, “random”}, default=”best”\n",
    "- \"best\" evaluates every split using criterion then split the node with the best one while \"random\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bbdde0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 'younger random' decision tree against 'younger' test: 77.17391304347827\n",
      "Accuracy of 'older random' decision tree against 'younger' test: 64.13043478260869\n",
      "Accuracy of 'younger random' decision tree against 'older' test: 56.43564356435643\n",
      "Accuracy of 'older random' decision tree against 'older' test: 70.29702970297029\n"
     ]
    }
   ],
   "source": [
    "younger_random_decisionTree_model = create_decision_tree(splitter='random')\n",
    "older_random_decisionTree_model = create_decision_tree(splitter='random')\n",
    "\n",
    "fit_decision_tree(younger_X_train, younger_y_train, younger_random_decisionTree_model)\n",
    "fit_decision_tree(older_X_train, older_y_train, older_random_decisionTree_model)\n",
    "\n",
    "younger_random_pred = test_decision_tree(younger_random_decisionTree_model, younger_X_test)\n",
    "younger_random_pred_opposite = test_decision_tree(younger_random_decisionTree_model, older_X_test)\n",
    "\n",
    "older_random_pred = test_decision_tree(older_random_decisionTree_model, older_X_test)\n",
    "older_random_pred_opposite = test_decision_tree(older_random_decisionTree_model, younger_X_test)\n",
    "\n",
    "print(\"Accuracy of 'younger random' decision tree against 'younger' test:\", calculate_accuracy(younger_y_test, younger_random_pred))\n",
    "print(\"Accuracy of 'older random' decision tree against 'younger' test:\", calculate_accuracy(younger_y_test, older_random_pred_opposite))\n",
    "print(\"Accuracy of 'younger random' decision tree against 'older' test:\", calculate_accuracy(older_y_test, younger_random_pred_opposite))\n",
    "print(\"Accuracy of 'older random' decision tree against 'older' test:\", calculate_accuracy(older_y_test, older_random_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b49933",
   "metadata": {},
   "source": [
    "### Decision Tree Max Depth\n",
    "- int or None, optional (default = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36b212ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree_accuracy_dict = {}\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "for x in range(4, 14):\n",
    "    younger_depth_decisionTree_model = create_decision_tree(max_depth=x)\n",
    "    older_depth_decisionTree_model = create_decision_tree(max_depth=x)\n",
    "    \n",
    "    fit_decision_tree(younger_X_train, younger_y_train, younger_depth_decisionTree_model)\n",
    "    fit_decision_tree(older_X_train, older_y_train, older_depth_decisionTree_model)\n",
    "    \n",
    "    younger_depth_pred = test_decision_tree(younger_depth_decisionTree_model, younger_X_test)\n",
    "    younger_depth_pred_opposite = test_decision_tree(younger_depth_decisionTree_model, older_X_test)\n",
    "    \n",
    "    older_depth_pred = test_decision_tree(older_depth_decisionTree_model, older_X_test)\n",
    "    older_depth_pred_opposite = test_decision_tree(older_depth_decisionTree_model, younger_X_test)\n",
    "    \n",
    "    tree_accuracy_dict['younger'] = calculate_accuracy(younger_y_test, younger_depth_pred)\n",
    "    tree_accuracy_dict['younger opposite'] = calculate_accuracy(older_y_test, younger_depth_pred_opposite)\n",
    "    tree_accuracy_dict['older'] = calculate_accuracy(older_y_test, older_depth_pred)\n",
    "    tree_accuracy_dict['older opposite'] = calculate_accuracy(younger_y_test, older_depth_pred_opposite)\n",
    "    \n",
    "    ax.bar(tree_accuracy_dict.keys(), tree_accuracy_dict.values(), width = 0.25)\n",
    "plt.legend(labels=range(4, 14))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f4a95",
   "metadata": {},
   "source": [
    "# WHY did they disagreed on those cases?\n",
    "- Use feature_importance\n",
    "- Train a new classifier which has new labels e.g. train on the same dataset but use for comparison but the labels will be whether they disagree or not...\n",
    "- The datasets we used for comparison was younger_X_test\n",
    "- Whether they disagree or not (the labels = np.logical_xor(older_y_pred_opposite, younger_y_pred)) this is the TARGET\n",
    "- Don't train/test split just use all of them for training!! \n",
    "- For this ML classifier, print feature_importance_ (high importance tells me why they disagreed)\n",
    "- No decision tree? Use logistic regression..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82420afa",
   "metadata": {},
   "source": [
    "# Print feature_importance_ of younger testcases classifier\n",
    "- This tells me which features effected how significantly on making disagreement between classifiers\n",
    "- They are computed as the mean and standard deviation of accumulation of the impurity decrease within tree\n",
    "- The importance of a feature is: how much this feature is used in tree. Formally, it is computed as the (normalized) total reduction of the criterion brought by that feature\n",
    "-- source: https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "-- source: https://inria.github.io/scikit-learn-mooc/python_scripts/dev_features_importance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc49d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the disagreed cases (i.e. either when A right but B wrong / A wrong but B right)\n",
    "younger_disagreed_testcases = return_disagreed_cases(younger_X_test, older_y_pred_opposite, younger_y_pred)\n",
    "younger_agreed_testcases = return_agreed_cases(younger_X_test, older_y_pred_opposite, younger_y_pred)\n",
    "\n",
    "all_younger_testcases = pd.DataFrame(younger_disagreed_testcases.append(younger_agreed_testcases))\n",
    "\n",
    "# don't test this ML classifier\n",
    "# data of X (predictors)\n",
    "younger_testcases_X_train = all_younger_testcases[features]\n",
    "\n",
    "# data of Y (target)\n",
    "younger_testcases_y_train = all_younger_testcases['Agreed']\n",
    "\n",
    "younger_testcases_decisionTree_model = create_decision_tree() # explore this later to justify why depth=10 (could be 5? or smaller)\n",
    "\n",
    "# train(fit) decision tree classifier\n",
    "\n",
    "fit_decision_tree(younger_testcases_X_train, younger_testcases_y_train, younger_testcases_decisionTree_model)\n",
    "\n",
    "print_feature_importance(younger_testcases_decisionTree_model, features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50a00f",
   "metadata": {},
   "source": [
    "# Print feature_importance_ of older testcases classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the disagreed cases (i.e. either when A right but B wrong / A wrong but B right)\n",
    "older_disagreed_testcases = return_disagreed_cases(older_X_test, younger_y_pred_opposite, older_y_pred)\n",
    "older_agreed_testcases = return_agreed_cases(older_X_test, younger_y_pred_opposite, older_y_pred)\n",
    "\n",
    "all_older_testcases = pd.DataFrame(older_disagreed_testcases.append(older_agreed_testcases))\n",
    "\n",
    "# don't test this ML classifier\n",
    "# data of X (predictors)\n",
    "older_testcases_X_train = all_older_testcases[features]\n",
    "\n",
    "# data of Y (target)\n",
    "older_testcases_y_train = all_older_testcases['Agreed']\n",
    "\n",
    "older_testcases_decisionTree_model = create_decision_tree() # explore this later to justify why depth=10 (could be 5? or smaller)\n",
    "\n",
    "# train(fit) decision tree classifier\n",
    "\n",
    "fit_decision_tree(older_testcases_X_train, older_testcases_y_train, older_testcases_decisionTree_model)\n",
    "\n",
    "print_feature_importance(older_testcases_decisionTree_model, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bebd25",
   "metadata": {},
   "source": [
    "# In which feature does each classifier rely on most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ebb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "younger_importance=print_feature_importance(younger_decisionTree_model, features)\n",
    "print(\"\\n\")\n",
    "older_importance=print_feature_importance(older_decisionTree_model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how the two different classifiers rely on features\n",
    "print(younger_importance - older_importance)\n",
    "print(\"The output tells me Pregnancies, BloodPressure, Insulin and BMI features were more important in younger classifier\")\n",
    "print(\"While Glucose, DiabetesPedigreeFunction and Age features were more important in Older\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c8eff",
   "metadata": {},
   "source": [
    "# Lime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb413d35",
   "metadata": {},
   "source": [
    "-- Younger\n",
    "- Left shows prediction probability of the two classes\n",
    "- The middle chart shows the important features with their bounding values and the right table is the actual corresponding feature value in the observation row passed\n",
    "-- source: https://towardsdatascience.com/a-guide-to-interpretable-machine-learning-2-fa3c4489fb53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d264215",
   "metadata": {},
   "source": [
    "# Explain for each classifier why they showed disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0936b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train using test cases where the labels are Agree and Disagree (0 and 1)\n",
    "all_disagreed_testcases = pd.DataFrame(younger_disagreed_testcases.append(older_disagreed_testcases))\n",
    "all_disagreed_testcases['Agreed'] = 0\n",
    "all_agreed_testcases = pd.DataFrame(younger_agreed_testcases.append(older_agreed_testcases))\n",
    "all_agreed_testcases['Agreed'] = 1\n",
    "\n",
    "# younger_disagreed + older_disagreed + younger_agreed + older_agreed\n",
    "all_testcases = pd.DataFrame(all_agreed_testcases.append(all_disagreed_testcases))\n",
    "\n",
    "# specify decision tree model\n",
    "all_testcases_decisionTree_model = create_decision_tree() # explore this later to justify why depth=10 (could be 5? or smaller)\n",
    "\n",
    "all_testcases_train = all_testcases[features]\n",
    "\n",
    "# train(fit) decision tree classifier\n",
    "all_testcases_decisionTree_model.fit(all_testcases_train, all_testcases.Agreed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c266226",
   "metadata": {},
   "source": [
    "### 1. Pick a random disagreed (all) testcases datapoint + Predict the outcome (Agreed/Disagreed) on each decision tree\n",
    "- by testing on both younger_decisiontree_model and older_decisiontree_model, show they results differently (one says diabetes while other says no diabetes) with LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed3a67",
   "metadata": {},
   "source": [
    "### Debugging for LIME explainer.as_list()\n",
    "- exp.as_list takes as its parameter the label for which you want an explanation. Since you're calling explain_instance with top_labels=1, it only produces an explanation for the top prediction of new_clf. If that is label 1, exp.as_list() will work, as the default parameter is one. If it is not, you'll get a key error. Your options:\n",
    "\n",
    "- If you're doing binary classification, don't use the top_labels parameter. You'll always get explanations for label 1\n",
    "- If it's multilabel classification, call exp.as_list(new_clf.predict(samp.as_matrix())[0])\n",
    "- If you want multiple explanations for different labels, call explain_instance with top_labels=num_labels\n",
    "- Source: https://github.com/marcotcr/lime/issues/106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bfb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Disagreed','Agreed']\n",
    "\n",
    "younger_X_train_numpy = younger_X_train.to_numpy()\n",
    "all_disagreed_testcases_numpy = all_disagreed_testcases[features].to_numpy()\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(younger_X_train_numpy,\n",
    "                                                   feature_names=features,\n",
    "                                                   class_names=classes,\n",
    "                                                   discretize_continuous=True)\n",
    "\n",
    "i = np.random.randint(0, len(all_disagreed_testcases_numpy))\n",
    "\n",
    "older_X_train_numpy = older_X_train.to_numpy()\n",
    "exp1 = explainer.explain_instance(all_disagreed_testcases_numpy[i], younger_decisionTree_model.predict_proba, num_features=8)\n",
    "exp1_list = exp1.as_list()\n",
    "print(exp1.as_map())\n",
    "print('\\n')\n",
    "print(exp1_list)\n",
    "exp1.show_in_notebook()\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(older_X_train_numpy,\n",
    "                                                   feature_names=features,\n",
    "                                                   class_names=classes,\n",
    "                                                   discretize_continuous=True)\n",
    "\n",
    "exp2 = explainer.explain_instance(all_disagreed_testcases_numpy[i], older_decisionTree_model.predict_proba, num_features=8)\n",
    "exp2_list = exp2.as_list()\n",
    "print(exp2.as_map())\n",
    "print('\\n')\n",
    "print(exp2_list)\n",
    "exp2.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(younger_decisionTree_model.predict(all_disagreed_testcases_numpy[i].reshape(1, -1)))\n",
    "print(older_decisionTree_model.predict(all_disagreed_testcases_numpy[i].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f780a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_map = exp1.as_map()[1]\n",
    "exp1_map.sort()\n",
    "exp2_map = exp2.as_map()[1]\n",
    "exp2_map.sort()\n",
    "exp1_map_df = pd.DataFrame(exp1_map)\n",
    "exp2_map_df = pd.DataFrame(exp2_map)\n",
    "exp1_map_df[0] = features\n",
    "exp2_map_df[0] = features\n",
    "\n",
    "# exp1_map_df\n",
    "# ax = exp1_map_df.plot(x=0, y=1, kind='barh', figsize=(10,8), legend=False, xlabel='Features', ylabel='Values')\n",
    "# exp2_map_df.plot(x=0, y=1, ax=ax, kind='barh', figsize=(10,8), legend=False, xlabel='Features', ylabel='Values')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for frame in [exp1_map_df, exp2_map_df]:\n",
    "    plt.barh(frame[0], frame[1])\n",
    "plt.legend([\"AAA\", \"BBB\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp1_map_df\n",
    "ax = exp1_map_df.plot(x=0, y=1, kind='barh',xlabel='Features',color='r')\n",
    "exp2_map_df.plot(x=0, y=1, ax=ax, kind='barh',xlabel='Features')\n",
    "plt.legend([\"AAA\", \"BBB\"]); # which one is agreed and disagreed?\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b408204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(exp1_list).plot(x =0, y=1, kind='barh', figsize=(10,8), legend=False, xlabel='Features', ylabel='Values', sort_columns=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc950d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(exp2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e81480",
   "metadata": {},
   "source": [
    "# Sankey diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: agreed and disagreed from younger - all_younger_testcases\n",
    "# target: agreed and disagreed from older - all_older_testcases\n",
    "# all_younger_testcases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = [\"Younger Diabetes Model\", \"Older Diabetes Model\", \"Agreed\", \"Disagreed\"],\n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = [0, 1, 1, 0],\n",
    "      target = [2, 2, 3, 3],\n",
    "      value = [len(younger_agreed_testcases), len(older_agreed_testcases), len(older_disagreed_testcases), len(younger_disagreed_testcases)]\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Sankey Diagram\", font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934c9b44",
   "metadata": {},
   "source": [
    "labels = [class1_v1, class2_v1, …classk_v1,\n",
    "          class1, class2, …, classk, \n",
    "               class1_v2, class2_v2, …, classk_v2] // 3k labels <br>\n",
    "\n",
    "Source = [0, 0, …, 0, 1,1,..., 1, … {k blocks}, \n",
    "\t    k, k, …, k, k+1, k+1, …, k+1, k+2, … ] // k*k*2 <br>\n",
    "        \n",
    "Target = [k, k+1, …, 2k {each of the ground truth classes}, k, k+1, …,{k blocks of k length}\n",
    "                2k, 2k+1, …, 3k-1, 2k, 2k+1, …, 3k-1, … {k blocks of k length} ] // k*k*2 <br>\n",
    "                \n",
    "Value = [num(predicted class1 by v1 that are of class1), \n",
    "              num(predicted class1 by v1 that are of class2), …,\n",
    "              num(predicted class1 by v1 that are of classk),\n",
    "\t…,\n",
    "              num(class 1 where v2 predicted class1), {source k to target 2k}\n",
    "              num(class 1 where v2 predicted class2), {source k to target 2k+1}…,\n",
    "              num(class 1 where v2 predicted classk),\n",
    "              … ] // k*k*2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = confusion_matrix(younger_y_test, younger_y_pred)\n",
    "print(len(younger_y_pred))\n",
    "print(output[0][0]) # true negatives\n",
    "print(output[0][1]) # false positives - not positive but output positive\n",
    "print(output[1][0]) # false negatives - not negative but output negative\n",
    "print(output[1][1]) # true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36192f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# older_y_pred_opposite = test_decision_tree(older_decisionTree_model, younger_X_test)\n",
    "# younger_y_pred = test_decision_tree(younger_decisionTree_model, younger_X_test)\n",
    "\n",
    "older_y_pred_opposite_confusion = confusion_matrix(younger_y_test, younger_y_pred)\n",
    "younger_y_pred_confusion = confusion_matrix(younger_y_test, older_y_pred_opposite)\n",
    "\n",
    "labels = ['Younger Diabetes', 'Younger No Diabetes', 'Diabetes', 'No Diabetes', 'Older Diabetes', 'Older No Diabetes']\n",
    "sources = [0, 0, 1, 1, 4, 4, 5, 5] \n",
    "targets = [2, 3, 2, 3, 2, 3, 2, 3]\n",
    "\n",
    "# num(predicted class1 by v1 that are of class1), \n",
    "#               num(predicted class1 by v1 that are of class2), …,\n",
    "\n",
    "values = [younger_y_pred_confusion[1][1], younger_y_pred_confusion[1][0],\n",
    "          younger_y_pred_confusion[0][1], younger_y_pred_confusion[0][0],\n",
    "          older_y_pred_opposite_confusion[1][1], older_y_pred_opposite_confusion[1][0],\n",
    "          older_y_pred_opposite_confusion[0][1], older_y_pred_opposite_confusion[0][0],]\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = labels,\n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = sources,\n",
    "      target = targets,\n",
    "      value = values\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Sankey Diagram\", font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172651e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(younger_y_test))\n",
    "younger_incorrect_testcases = younger_X_test[np.logical_xor(younger_y_test.to_numpy(), younger_y_pred)]\n",
    "younger_correct_testcases = younger_X_test.loc[younger_X_test.index.difference(younger_incorrect_testcases.index)]\n",
    "\n",
    "older_incorrect_testcases = older_X_test[np.logical_xor(older_y_test.to_numpy(), older_y_pred)]\n",
    "older_correct_testcases = older_X_test.loc[older_X_test.index.difference(older_incorrect_testcases.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2e468",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226319d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_prediction = all_testcases_train.iloc[1]\n",
    "data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n",
    "\n",
    "print(all_testcases_decisionTree_model.predict_proba(data_for_prediction_array))\n",
    "\n",
    "shap_explainer = shap.TreeExplainer(all_testcases_decisionTree_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = shap_explainer.shap_values(data_for_prediction)\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value[1], shap_values[1], data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fcc3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_explainer = shap.TreeExplainer(all_testcases_decisionTree_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = shap_explainer.shap_values(all_testcases_train)\n",
    "shap.initjs()\n",
    "shap.force_plot(shap_explainer.expected_value[1], shap_values[1], all_testcases_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_explainer = shap.TreeExplainer(all_testcases_decisionTree_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = shap_explainer.shap_values(all_testcases['Agreed'])\n",
    "shap.initjs()\n",
    "# shap.force_plot(explainer.expected_value[0], shxap_values[0][i], X.values[i], feature_names = X.columns)\n",
    "shap.force_plot(shap_explainer.expected_value[0], shap_values[0][0], all_testcases['Agreed'][0],feature_names = all_testcases.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap_explainer = shap.TreeExplainer(younger_decisionTree_model)\n",
    "shap_values = shap_explainer.shap_values(younger_X)\n",
    "shap.summary_plot(shap_values, younger_X, plot_type=\"bar\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap_explainer = shap.TreeExplainer(older_decisionTree_model)\n",
    "shap_values = shap_explainer.shap_values(older_X)\n",
    "shap.summary_plot(shap_values, older_X, plot_type=\"bar\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "all_testcases = pd.DataFrame(all_agreed_testcases.append(all_disagreed_testcases))\n",
    "\n",
    "shap_explainer = shap.TreeExplainer(all_testcases_decisionTree_model)\n",
    "shap_values = shap_explainer.shap_values(all_testcases[features])\n",
    "shap.summary_plot(shap_values, all_testcases[features], plot_type=\"bar\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e01ba",
   "metadata": {},
   "source": [
    "# Visualise decision trees\n",
    "-- Source: https://mljar.com/blog/visualize-decision-tree/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332df7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,20))\n",
    "youngTreeVisualisation = tree.plot_tree(younger_decisionTree_model, feature_names=features, class_names=['0','1'], filled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95792dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,20))\n",
    "oldTreeVisualisation = tree.plot_tree(older_decisionTree_model, feature_names=features, class_names=str(olderDiabetes.Outcome), filled=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
